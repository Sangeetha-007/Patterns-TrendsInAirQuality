# -*- coding: utf-8 -*-
"""602 proposal.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-Amv399QZ2EL2tBXjsdPUkIScNPg26t2

# Abstract
Reducing harmful contaminants in the air has been a pressing issue due to pollution and the effects of climate change. In our study, we are going to analyze temporal patterns and trends in humidity based on pollutants (CO, Non Metanic Hydrocarbons, Benzene, NOx, NO2) over the one-year recording period. Our work is based on the dataset about Air Quality from UCI Machine Learning Repository, where the data was collected from a city in Italy.

# Introduction
The escalating concerns surrounding environmental degradation, fueled by pollution and the consequential impacts of climate change, have placed the imperative of mitigating harmful contaminants in the air at the forefront of global agendas. Recognizing the critical need for comprehensive assessments in this domain, our study embarks on a thorough examination of temporal patterns and trends in key humidity indicators—specifically, Carbon Monoxide (CO), Non-Methanic Hydrocarbons, Benzene, Nitrogen Oxides (NOx), and Nitrogen Dioxide (NO2). Over the course of a one-year recording period, our investigation aims to shed light on the dynamic nature of these pollutants and their variations over time.


The foundation of our research lies in the dataset sourced from the UCI Machine Learning Repository, specifically curated to capture intricate details of air quality dynamics. The data was collected from a city in Italy. As we delve into the analysis of this dataset, our goal is to not only discern temporal patterns but also to unravel trends that could provide valuable insights into the factors influencing humidity fluctuations. By leveraging this dataset, we seek to contribute meaningful information that can inform policy decisions, urban planning strategies, and environmental interventions aimed at curbing the adverse effects of air pollution.


Through this study, we aspire to deepen our understanding of the complex interplay between anthropogenic activities and humidity dynamics. Such insights are crucial for developing targeted and effective measures to address the pressing issue of the impacts of climate change on our atmospheric environment and find ways to prevent or improve our global temperatures.

Dataset Columns :
*   0 Date (DD/MM/YYYY)
*   1 Time (HH.MM.SS)
*   2 True hourly averaged concentration CO in mg/m^3 (reference analyzer)
*   3 PT08.S1 (tin oxide) hourly averaged sensor response (nominally CO targeted)
*   4 True hourly averaged overall Non Metanic HydroCarbons concentration in microg/m^3 (reference analyzer)
*   5 True hourly averaged Benzene concentration in microg/m^3 (reference analyzer)
*   6 PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)
*   7 True hourly averaged NOx concentration in ppb (reference analyzer)
*   8 PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted)
*   9 True hourly averaged NO2 concentration in microg/m^3 (reference analyzer)
*   10 PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)
*   11 PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)
*   12 Temperature in Ã‚Â°C
*   13 Relative Humidity (%)
*   14 AH Absolute Humidity
"""

import pandas as pd

# URL of the CSV file
url = "https://archive.ics.uci.edu/static/public/360/data.csv"

# Reading the CSV file into a DataFrame
df = pd.read_csv(url)

# Displaying the DataFrame
print(df)

df.info()

df.head()

df.describe()

""" Histogram for CO(GT)"""

# Let's create some well-labeled visualizations for exploratory data analysis.
import seaborn as sns
import matplotlib.pyplot as plt

# Setting the style
sns.set(style="whitegrid")

# Plotting the histogram
plt.figure(figsize=(10, 6))
sns.histplot(df['CO(GT)'], bins=30, kde=True, color='blue')
plt.title('Distribution of CO(GT)')
plt.xlabel('CO(GT)')
plt.ylabel('Frequency')
plt.show()

"""Box Plot for PT08.S1(CO)"""

plt.figure(figsize=(10, 6))
sns.boxplot(x=df['PT08.S1(CO)'], color='green')
plt.title('Box Plot of PT08.S1(CO)')
plt.xlabel('PT08.S1(CO)')
plt.show()

"""Pair Plot for Selected Variables"""

# Selecting relevant variables for pair plot
selected_vars = ['CO(GT)', 'PT08.S1(CO)', 'C6H6(GT)', 'T', 'RH']

# Pair plot
sns.pairplot(df[selected_vars])
plt.suptitle('Pair Plot of Selected Variables', y=1.02)
plt.show()

"""It seems like there are missing values represented by -200 in several columns. Before continuing creating visualizations, it's a good idea to handle these missing values. We can replace them with NaN and then decide how to deal with them, either by removing or imputing.

# Data Wrangling

# Data Wrangling
"""

# Calculate the count of NA values for each column
na_count_per_column = df.isna().sum()

# Display the count of NA values for each column
print("Count of NA Values for Each Column:")
print(na_count_per_column)

"""Even though there are no NA values, it seems from above that there are a lot of -200 values which may represent the missing values, so I am going to find a way to count them.

"""

# Specify the number you want to count
number_to_count = -200

# Count occurrences of the specified number in each column
count_of_number_per_column = df.apply(lambda x: x.eq(number_to_count).sum())

# Display the counts of the specified number in each column
print("\nCount of Number {} in Each Column:".format(number_to_count))
print(count_of_number_per_column)

"""In order to figure that out, I am going to look at summary statistics again."""

df.describe()

"""For the first column, CO(GT) is the True hourly averaged concentration CO in mg/m^3. Negative values in air quality data might indicate measurement errors, calibration issues, or other problems with the monitoring equipment. It's crucial to carefully review and validate air quality data to identify and correct any anomalies or errors. The mean for this field is -34 currently, but since negative values indicate an error, we can't use the mean."""

from scipy.stats import mode
# Calculate the mode
result = mode(df['CO(GT)'])

print("Mode:", result)

# Deep copy (changes to the original will not affect the copy and vice versa)
deep_copied_df = df.copy(deep=True)

# Specify the number you want to count
number_to_count = -200

# Count occurrences of the specified number in each column
count_of_number_per_column = deep_copied_df.apply(lambda x: x.eq(number_to_count).sum())

# Display the counts of the specified number in each column
print("\nCount of Number {} in Each Column:".format(number_to_count))
print(count_of_number_per_column)

deep_copied_df = deep_copied_df[deep_copied_df['CO(GT)'] != -200]

# Specify the number you want to count
number_to_count = -200

# Count occurrences of the specified number in each column
count_of_number_per_column = deep_copied_df.apply(lambda x: x.eq(number_to_count).sum())

# Display the counts of the specified number in each column
print("\nCount of Number {} in Each Column:".format(number_to_count))
print(count_of_number_per_column)

deep_copied_df.describe()

"""After making a copy of the dataframe and dropping the rows with -200 for the 'CO(GT)' field, we can see the mean is 2.152750. Now, we can go back to the original dataframe and impute this value for -200."""

df['CO(GT)'] = df['CO(GT)'].replace(-200, 2.152750)
# Specify the number you want to count
number_to_count = -200

# Count occurrences of the specified number in each column
count_of_number_per_column = df.apply(lambda x: x.eq(number_to_count).sum())

# Display the counts of the specified number in each column
print("\nCount of Number {} in Each Column:".format(number_to_count))
print(count_of_number_per_column)

"""Now, that CO('GT') has been cleaned up, next we will look at PT08.S1(CO) . It is the measurment of the concentration of tin oxide in the air."""

deep_copied_df = deep_copied_df[deep_copied_df['PT08.S1(CO)'] != -200]

# Specify the number you want to count
number_to_count = -200

# Count occurrences of the specified number in each column
count_of_number_per_column = deep_copied_df.apply(lambda x: x.eq(number_to_count).sum())

# Display the counts of the specified number in each column
print("\nCount of Number {} in Each Column:".format(number_to_count))
print(count_of_number_per_column)
deep_copied_df.describe()

"""Again, I am replacing -200 with the mean of PT08.S1(CO), which is 1110.580746"""

df['PT08.S1(CO)'] = df['PT08.S1(CO)'].replace(-200, 1110.580746)
# Specify the number you want to count
number_to_count = -200

# Count occurrences of the specified number in each column
count_of_number_per_column = df.apply(lambda x: x.eq(number_to_count).sum())

# Display the counts of the specified number in each column
print("\nCount of Number {} in Each Column:".format(number_to_count))
print(count_of_number_per_column)

"""After cleaning up the PT08.S1(CO) field, now I am going to clean up the 'NMHC(GT)' column. Since there are 8443 rows of missing data, I am just going to drop the column."""

df = df.drop(columns='NMHC(GT)')

"""Now, I am going to clean up the C6H6(GT) field, which represents the true hourly averaged Benzene concentration in microg/m^3"""

# Deep copy (changes to the original will not affect the copy and vice versa)
deep_copied_df = df.copy(deep=True)

deep_copied_df = deep_copied_df[deep_copied_df['C6H6(GT)'] != -200]

# Specify the number you want to count
number_to_count = -200

# Count occurrences of the specified number in each column
count_of_number_per_column = deep_copied_df.apply(lambda x: x.eq(number_to_count).sum())

# Display the counts of the specified number in each column
print("\nCount of Number {} in Each Column:".format(number_to_count))
print(count_of_number_per_column)
deep_copied_df.describe()

df['C6H6(GT)'] = df['C6H6(GT)'].replace(-200, 10.083105	)
df.describe()

# Specify the number you want to count
number_to_count = -200

# Count occurrences of the specified number in each column
count_of_number_per_column = df.apply(lambda x: x.eq(number_to_count).sum())
print(count_of_number_per_column)

# Deep copy (changes to the original will not affect the copy and vice versa)
deep_copied_df = df.copy(deep=True)

deep_copied_df = deep_copied_df[deep_copied_df['PT08.S2(NMHC)'] != -200]

# Specify the number you want to count
number_to_count = -200

# Count occurrences of the specified number in each column
count_of_number_per_column = deep_copied_df.apply(lambda x: x.eq(number_to_count).sum())

# Display the counts of the specified number in each column
print("\nCount of Number {} in Each Column:".format(number_to_count))
print(count_of_number_per_column)
deep_copied_df.describe()

df['PT08.S2(NMHC)'] = df['PT08.S2(NMHC)'].replace(-200, 939.153376)
df.describe()

# Specify the number you want to count
number_to_count = -200

# Count occurrences of the specified number in each column
count_of_number_per_column = df.apply(lambda x: x.eq(number_to_count).sum())
print(count_of_number_per_column)

# Deep copy (changes to the original will not affect the copy and vice versa)
deep_copied_df = df.copy(deep=True)

deep_copied_df = deep_copied_df[deep_copied_df['NOx(GT)'] != -200]

# Specify the number you want to count
number_to_count = -200

# Count occurrences of the specified number in each column
count_of_number_per_column = deep_copied_df.apply(lambda x: x.eq(number_to_count).sum())

# Display the counts of the specified number in each column
print("\nCount of Number {} in Each Column:".format(number_to_count))
print(count_of_number_per_column)
deep_copied_df.describe()

df['NOx(GT)'] = df['NOx(GT)'].replace(-200, 246.896735)
df.describe()

# Specify the number you want to count
number_to_count = -200

# Count occurrences of the specified number in each column
count_of_number_per_column = df.apply(lambda x: x.eq(number_to_count).sum())
print(count_of_number_per_column)

# Deep copy (changes to the original will not affect the copy and vice versa)
deep_copied_df = df.copy(deep=True)

# Remove rows where any column contains the value -200
deep_copied_df = deep_copied_df[~deep_copied_df.eq(-200).any(axis=1)]

# The resulting DataFrame now has rows removed where any column had the value -200
deep_copied_df.describe()

df['PT08.S3(NOx)'] = df['PT08.S3(NOx)'].replace(-200, 973.875441)


# Specify the number you want to count
number_to_count = -200

# Count occurrences of the specified number in each column
#count_of_number_per_column = df.apply(lambda x: x.eq(number_to_count).sum())
#print(count_of_number_per_column)

###########################
df['NO2(GT)'] = df['NO2(GT)'].replace(-200, 99.002350)
df.describe()
###########################
df['PT08.S4(NO2)'] = df['PT08.S4(NO2)'].replace(-200, 1592.470035)
df.describe()
###########################
df['PT08.S5(O3)'] = df['PT08.S5(O3)'].replace(-200, 1036.462985)
df.describe()
###########################
df['T'] = df['T'].replace(-200, 15.486134)
df.describe()
###########################
df['RH'] = df['RH'].replace(-200, 49.409636)
df.describe()
###########################
df['AH'] = df['AH'].replace(-200, 0.832032)
df.describe()
# Count occurrences of the specified number in each column
count_of_number_per_column = df.apply(lambda x: x.eq(number_to_count).sum())
print(count_of_number_per_column)

"""# Data Analysis"""

df

df.describe()

df.info()

# Correlation Heatmap
plt.figure(figsize=(12, 8))
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

"""Positive correlations:

Correlation between 'PT08.S2' and 'C6H6':

As the sensor response ('PT08.S2') increases, the concentration of Benzene ('C6H6') also tends to increase.
This correlation might indicate that the sensor targeted for Non Metanic Hydrocarbons (NMHC) is responsive to Benzene, as NMHCs often include compounds like Benzene.


Correlation between 'C6H6' and 'CO':

It may suggest a common source or shared factors influencing the levels of both Benzene and Carbon Monoxide.
For example, certain combustion processes, such as incomplete burning of fossil fuels, can release both Benzene and Carbon Monoxide into the air.

Correlation between 'PT08.S2' and 'PT08.S1':

This correlation may suggest that the sensor targeted for Non Metanic Hydrocarbons is responding to some of the same compounds as the sensor targeted for  Carbon Monoxide CO. This could be due to shared components in the air that contribute to both NMHC and CO concentrations.





"""

# Calculating the rolling average
rolling_avg = df['CO(GT)'].rolling(window=30, min_periods=1).mean()

# Plotting the original and rolling average
plt.figure(figsize=(14, 8))
plt.plot(df['CO(GT)'], label='Original')
plt.plot(rolling_avg, label='Rolling Average (30 days)')
plt.title('Original vs. Rolling Average of CO(GT)')
plt.xlabel('Date')
plt.ylabel('Concentration')
plt.legend()
plt.show()

"""This graph compares the original 'CO(GT)' values with their 30-day rolling average, it provides valuable insights into the long-term trends and variations in carbon monoxide concentration over time.

Seasonal changes, such as temperature fluctuations or changes in weather patterns, can impact air quality.


"""

import matplotlib.pyplot as plt
import seaborn as sns

# Converting 'Date' to datetime format
df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)

# Selecting relevant columns
selected_indicators = ['CO(GT)', 'C6H6(GT)', 'NOx(GT)', 'NO2(GT)']

# Plotting time series line plots
plt.figure(figsize=(14, 8))
for indicator in selected_indicators:
    sns.lineplot(data=df, x=df.index, y=indicator, label=indicator)

plt.title('Temporal Patterns of Air Quality Indicators')
plt.xlabel('Date')
plt.ylabel('Concentration')
plt.legend()
plt.show()

"""We observe more significant variations in air quality indicators during the winter of 2004 to 2005.

In colder months, there is often higher energy demand for heating, leading to increased combustion of fossil fuels. This can result in elevated levels of pollutants such as carbon monoxide (CO), nitrogen oxides (NOx), and particulate matter.
"""

df.columns

# Importing necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt


# Selecting features and target variable
features = ['PT08.S4(NO2)']
target = 'AH'

# Extracting features and target variable
X = df[features]
y = df[target]

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initializing the linear regression model
model = LinearRegression()

# Fitting the model to the training data
model.fit(X_train, y_train)

# Making predictions on the test set
y_pred = model.predict(X_test)

# Evaluating the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R-squared: {r2}')

# Plotting actual vs predicted values
plt.scatter(X_test, y_test, label='Actual')
plt.scatter(X_test, y_pred, label='Predicted')
plt.xlabel('PT08.S4(NO2) - Tungsten Oxide')
plt.ylabel('AH - Absolute Humidity')
plt.title('Actual vs Predicted AH based on PT08.S4(NO2)')
plt.legend()
plt.show()

"""Election for this model:

Humidity significantly impacts air quality by influencing chemical reactions, particle behavior, and human health. It plays a crucial role in the formation and transformation of pollutants, affects particle dispersion, and contributes to respiratory issues. Indoors, humidity levels influence mold growth and overall air quality. Meteorologically, it interacts with other factors, shaping atmospheric conditions. Predicting humidity using the PT08.S4(NO2) tungsten oxide sensor response is vital due to observed correlations. This modeling enhances our ability to interpret air quality data accurately, offering insights into how well sensor readings predict humidity, a key parameter in understanding and managing air quality.

Mean square error (MSE) is the average of the square of the errors. The larger the number the larger the error. We got a mean square of 0.099. We got an R squared of 0.378. A low value would show a low level of correlation.

# Conclusion

The analysis successfully revealed temporal patterns and trends in absolute humidity, providing a comprehensive view of their variations over time.
Seasonal changes, meteorological conditions, and potential anthropogenic influences could contribute to the observed patterns.

The insights gained from this analysis are valuable for understanding the dynamics of air quality, aiding in the identification of periods with elevated pollutant concentrations.
Further exploration and statistical modeling could enhance predictions and provide a more in-depth understanding of the factors driving humidity variations.

# Sources

*   https://archive.ics.uci.edu/dataset/387/air+quality
*   https://www.thelancet.com/journals/lanplh/article/PIIS2542-5196(21)00350-8/fulltext
*   https://www.nature.com/articles/s41598-019-56578-6
*   https://www.bmc.com/blogs/mean-squared-error-r2-and-variance-in-regression-analysis/
"""
